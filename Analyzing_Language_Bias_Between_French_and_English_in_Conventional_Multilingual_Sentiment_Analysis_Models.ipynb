{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethanwongca/COMP396/blob/main/Analyzing_Language_Bias_Between_French_and_English_in_Conventional_Multilingual_Sentiment_Analysis_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUHtqXc2ZW0k"
      },
      "source": [
        "# Calculating Bias for Multilingual Support Vector Machine and Naive-Bayes for Sentiment Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dXdDBb1ZmL3"
      },
      "source": [
        "## Library Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpyRc8zQLATi"
      },
      "source": [
        "Libraries Used:\n",
        "\n",
        "\n",
        "*   **Sklearn**: Used to use the Multinomial Naive-Bayes and Support Vector Machine Model, build the Tf-Idf Matrix, use proper train test splitting, and build accuracy reports.\n",
        "*   **Pandas**: Used for building DataFrames\n",
        "*   **Numpy**: Provides operations for the DataFrames\n",
        "*   **FairLearn**: Builds specified bias metrics in models\n",
        "\n",
        "Dependenices are available at **requirements.txt.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cfxLUN4KBZrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4309b092-afec-47c3-cc99-31fcc2c504be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fairlearn in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.25.2)\n",
            "Requirement already satisfied: pandas>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from fairlearn) (1.11.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->fairlearn) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.29)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install fairlearn\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ddtrk8DZm85",
        "outputId": "938b3169-49e0-4e1d-be9b-76694074650d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.datasets import make_classification\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from fairlearn.metrics import MetricFrame, demographic_parity_difference, equalized_odds_difference, selection_rate, equalized_odds_ratio, demographic_parity_ratio\n",
        "from google.colab import drive\n",
        "import optuna\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fek72E8dbPIH"
      },
      "source": [
        "## Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_6lGH_xVkK9"
      },
      "source": [
        "Installing spaCy's French and English stop words and pre-processing tools, removing taggers as dataset is unordered."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_9v_Ff5bN1-"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50yga7_wfDzD"
      },
      "outputs": [],
      "source": [
        "nlp_en = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
        "nlp_fr = spacy.load(\"fr_core_news_sm\", disable=[\"ner\", \"parser\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCIHpyzNiFZf"
      },
      "source": [
        "## Pre-Processing Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd_Y0PniW_8n"
      },
      "source": [
        "*   **Review Parsing** - Parses through the dataset and reconstructs the text from the word frequencies provided, along with the sentiment labels as well.\n",
        "*   **Batch Pre-Processing** - Pre-processes the text via spaCy using batch pre-processing with a batch size of 100.\n",
        "*   **Load Dataset** - The fully pre-process data is placed in a dataframe.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-QqVoBvFfeng"
      },
      "outputs": [],
      "source": [
        "def review_parsing(line):\n",
        "    \"\"\"\n",
        "    Parses lines from the dataset to reconstruct the text by multiplying by the\n",
        "    proper word frequencies and extracting the sentiment labels as well.\n",
        "\n",
        "    Args:\n",
        "      String: The lines in the dataset\n",
        "\n",
        "    Returns:\n",
        "      Dict {str:str}: A dictionary that has text and sentiment as the keys and\n",
        "      the reconstructed text and sentiment as values.\n",
        "    \"\"\"\n",
        "    words = []\n",
        "    parts = line.strip().split()\n",
        "    sentiment = None\n",
        "\n",
        "    for part in parts:\n",
        "        if part.startswith(\"#label#\"):\n",
        "            sentiment = part.split(\":\")[1]\n",
        "        else:\n",
        "            word, freq = part.split(\":\")\n",
        "            words.extend([word] * int(freq))\n",
        "\n",
        "    reconstructed_text = \" \".join(words)\n",
        "    return {'text': reconstructed_text, 'sentiment': sentiment}\n",
        "\n",
        "def batch_preprocess_en(texts):\n",
        "    \"\"\"\n",
        "    Batch pre-process English texts.\n",
        "\n",
        "    Args:\n",
        "      List[str]: All of the English texts.\n",
        "\n",
        "    Return:\n",
        "      List[str]: All of the English texts fully pre-processed.\n",
        "    \"\"\"\n",
        "    processed_texts = []\n",
        "    for doc in nlp_en.pipe(texts, batch_size=100):\n",
        "        tokens = [token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop]\n",
        "        processed_texts.append(' '.join(tokens))\n",
        "    return processed_texts\n",
        "\n",
        "def batch_preprocess_fr(texts):\n",
        "    \"\"\"\n",
        "    Batch pre-process French texts.\n",
        "\n",
        "    Args:\n",
        "      List[str]: All of the French texts.\n",
        "\n",
        "    Return:\n",
        "      List[str]: All of the French texts fully pre-processed.\n",
        "    \"\"\"\n",
        "    processed_texts = []\n",
        "    for doc in nlp_fr.pipe(texts, batch_size=20):\n",
        "        tokens = [token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop]\n",
        "        processed_texts.append(' '.join(tokens))\n",
        "    return processed_texts\n",
        "\n",
        "def load_dataset_to_dataframe_en(file_path):\n",
        "    \"\"\"\n",
        "    Transforming the English pre-processed data into a dataframe.\n",
        "\n",
        "    Args:\n",
        "      FILE: The CSV file with all the English data.\n",
        "\n",
        "    Return:\n",
        "      DataFrame: A dataframe that has the pre-processed texts along with the\n",
        "      sentiments.\n",
        "    \"\"\"\n",
        "    texts, sentiments = [], []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parsed_line = review_parsing(line)\n",
        "            texts.append(parsed_line['text'])\n",
        "            sentiments.append(parsed_line['sentiment'])\n",
        "\n",
        "    processed_texts = batch_preprocess_en(texts)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'ProcessedText': processed_texts,\n",
        "        'Sentiment': sentiments\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "def load_dataset_to_dataframe_fr(file_path):\n",
        "    \"\"\"\n",
        "    Transforming the French pre-processed data into a dataframe.\n",
        "\n",
        "    Args:\n",
        "      FILE: The CSV file with all the French data.\n",
        "\n",
        "    Return:\n",
        "      DataFrame: A dataframe that has the pre-processed texts along with the\n",
        "      sentiments.\n",
        "    \"\"\"\n",
        "    texts, sentiments = [], []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parsed_line = review_parsing(line)\n",
        "            texts.append(parsed_line['text'])\n",
        "            sentiments.append(parsed_line['sentiment'])\n",
        "\n",
        "    processed_texts = batch_preprocess_fr(texts)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'ProcessedText': processed_texts,\n",
        "        'Sentiment': sentiments\n",
        "    })\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZUeVjoTj3wS"
      },
      "source": [
        "## Loading the Particular Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2zaSdSAWQtY"
      },
      "source": [
        "The file path to the Webis-CLS-10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWhA43Zvj29K"
      },
      "outputs": [],
      "source": [
        "FILE_PATH_EN = '/content/drive/My Drive/dataset/en/music/unlabeled.processed'\n",
        "FILE_PATH_FR = '/content/drive/My Drive/dataset/fr/music/unlabeled.processed'\n",
        "\n",
        "FILE_PATH_EN_dvd = '/content/drive/My Drive/dataset/en/dvd/unlabeled.processed'\n",
        "FILE_PATH_FR_dvd = '/content/drive/My Drive/dataset/fr/dvd/unlabeled.processed'\n",
        "\n",
        "FILE_PATH_EN_books = '/content/drive/My Drive/dataset/en/books/unlabeled.processed'\n",
        "FILE_PATH_FR_books = '/content/drive/My Drive/dataset/fr/books/unlabeled.processed'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y49K0se-i4fi"
      },
      "source": [
        "Loading the French and English dataset from the Webis-CLS-10 Dataset. We are taking the all three sub-categories of the dataset which are the dvd, music, and books categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBgD0IPkl_1h"
      },
      "outputs": [],
      "source": [
        "data_en = load_dataset_to_dataframe_en(FILE_PATH_EN)\n",
        "data_fr = load_dataset_to_dataframe_fr(FILE_PATH_FR)\n",
        "\n",
        "data_en_dvd = load_dataset_to_dataframe_en(FILE_PATH_EN_dvd)\n",
        "data_fr_dvd = load_dataset_to_dataframe_fr(FILE_PATH_FR_dvd)\n",
        "\n",
        "data_en_books = load_dataset_to_dataframe_en(FILE_PATH_EN_books)\n",
        "data_fr_books = load_dataset_to_dataframe_fr(FILE_PATH_FR_books)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybirNvwGKBzu"
      },
      "source": [
        "## Caching the Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omf0WTj-WbFn"
      },
      "source": [
        "Caching the datasets so there is no need to keep pre-processing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woEyvlk3J-mr"
      },
      "outputs": [],
      "source": [
        "data_en.to_csv(\"/content/drive/My Drive/dataset/en/music/unlabeled_update.csv\", index=False)\n",
        "data_fr.to_csv(\"/content/drive/My Drive/dataset/fr/music/unlabeled_update.csv\", index=False)\n",
        "\n",
        "data_en_dvd.to_csv(\"/content/drive/My Drive/dataset/en/dvd/unlabeled_update.csv\", index=False)\n",
        "data_fr_dvd.to_csv(\"/content/drive/My Drive/dataset/fr/dvd/unlabeled_update.csv\", index=False)\n",
        "\n",
        "data_en_books.to_csv(\"/content/drive/My Drive/dataset/en/books/unlabeled_update.csv\", index=False)\n",
        "data_fr_books.to_csv(\"/content/drive/My Drive/dataset/fr/books/unlabeled_update.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "E7hq7-p2uJ1W"
      },
      "outputs": [],
      "source": [
        "data_en = pd.read_csv(\"/content/drive/My Drive/dataset/en/music/unlabeled_update.csv\")\n",
        "data_fr = pd.read_csv(\"/content/drive/My Drive/dataset/fr/music/unlabeled_update.csv\")\n",
        "\n",
        "data_en_dvd = pd.read_csv(\"/content/drive/My Drive/dataset/en/dvd/unlabeled_update.csv\")\n",
        "data_fr_dvd = pd.read_csv(\"/content/drive/My Drive/dataset/fr/dvd/unlabeled_update.csv\")\n",
        "\n",
        "data_en_books = pd.read_csv(\"/content/drive/My Drive/dataset/en/books/unlabeled_update.csv\")\n",
        "data_fr_books = pd.read_csv(\"/content/drive/My Drive/dataset/fr/books/unlabeled_update.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1gCKX0xzg52",
        "outputId": "e66e8122-d7fa-417e-e0e0-788bdaf02809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32870, 2)\n"
          ]
        }
      ],
      "source": [
        "print(data_fr_books.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEdKjA3tWymE"
      },
      "source": [
        "# The Dataset Pre-Processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "PaQyIBVEK0QA",
        "outputId": "2425bbec-351a-4087-b0db-f7fdf71f5a24"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                           ProcessedText Sentiment\n",
              "0      pretty pretty pretty good good good record rec...  negative\n",
              "1      classical alive year narration peter child you...  positive\n",
              "2      chamillionaire chamillionaire chamillionaire c...  negative\n",
              "3      perfect perfect giants giants world world linc...  positive\n",
              "4      play play playing playing autoharp autoharp au...  positive\n",
              "...                                                  ...       ...\n",
              "25215  num num num num num num num num num num num nu...  positive\n",
              "25216  album album album excuse excuse word word like...  positive\n",
              "25217  destiny destiny music music stone stone beauti...  negative\n",
              "25218  well well good tha tha tha rap rap hear hear r...  positive\n",
              "25219   lm cd wonder devil peace entitle sell kam happen  negative\n",
              "\n",
              "[25220 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5692b2ef-3258-4ca8-8d0b-97273f26f64f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProcessedText</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pretty pretty pretty good good good record rec...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>classical alive year narration peter child you...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chamillionaire chamillionaire chamillionaire c...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>perfect perfect giants giants world world linc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>play play playing playing autoharp autoharp au...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25215</th>\n",
              "      <td>num num num num num num num num num num num nu...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25216</th>\n",
              "      <td>album album album excuse excuse word word like...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25217</th>\n",
              "      <td>destiny destiny music music stone stone beauti...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25218</th>\n",
              "      <td>well well good tha tha tha rap rap hear hear r...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25219</th>\n",
              "      <td>lm cd wonder devil peace entitle sell kam happen</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25220 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5692b2ef-3258-4ca8-8d0b-97273f26f64f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5692b2ef-3258-4ca8-8d0b-97273f26f64f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5692b2ef-3258-4ca8-8d0b-97273f26f64f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8ca404e9-a796-4950-b9fb-e8a934bddc4c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ca404e9-a796-4950-b9fb-e8a934bddc4c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8ca404e9-a796-4950-b9fb-e8a934bddc4c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_946701cf-89b1-4dcf-b836-81224601d1eb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_en')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_946701cf-89b1-4dcf-b836-81224601d1eb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data_en');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_en",
              "summary": "{\n  \"name\": \"data_en\",\n  \"rows\": 25220,\n  \"fields\": [\n    {\n      \"column\": \"ProcessedText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21501,\n        \"samples\": [\n          \"know know know know rock rock rock rock album album album album kid kid kid kid like like like radio radio get get devil devil music music forget inovator bridge father num far big fan rocky solid stuff gap casual say play talant cash willie hag ask wait great talent country like trust impressed type ok true love listener love example go general prove play sure bruce friend tune old traditional time play\",\n          \"jeff jeff good good music music beal beal create create tone cd include title previous people melvoin theme win wendy coleman main correction show season compilation design post bad lisa emmy original\",\n          \"cd cd cd cd cd cd pbbb pbbb pbbb num num num album album album remastere remastered remastered domestic domestic import import elektra elektra buying buy money yes wea title worth inferior real mystery crabshaw ditto lose note domestically fabulous paul rothchild record version available remaster back great bob pigboy sound actually miss west music waste session release east version import incredible price wrong irwin liner dream original\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(data_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "p-yxckRsK68F",
        "outputId": "e4c2e9fb-6533-4f4e-8666-394fe42be78a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                           ProcessedText Sentiment\n",
              "0      ringard ringard ringard esrt aufray rêver fair...  negative\n",
              "1      l l l d d jamais jamais n n peur indépendanc t...  negative\n",
              "2      muse muse muse muse muse muse muse qu qu qu qu...  negative\n",
              "3      num num num num l l l groupe groupe groupe évo...  negative\n",
              "4      d d d d d d d sympa sympa sympa sympa sympa sy...  negative\n",
              "...                                                  ...       ...\n",
              "15935  d d rappeler dizain j année cd petit adore osu...  positive\n",
              "15936  vallenato vallenato vallenato rien rien modern...  negative\n",
              "15937  sambora sambora connaître guitarist album proc...  positive\n",
              "15938  disco disco n n compil qualité énorme passez c...  negative\n",
              "15939  médiocre cd traditionnel piste trouver que mus...  negative\n",
              "\n",
              "[15940 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53019092-1100-4b64-8466-4dd6769e2b91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProcessedText</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ringard ringard ringard esrt aufray rêver fair...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>l l l d d jamais jamais n n peur indépendanc t...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>muse muse muse muse muse muse muse qu qu qu qu...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>num num num num l l l groupe groupe groupe évo...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>d d d d d d d sympa sympa sympa sympa sympa sy...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15935</th>\n",
              "      <td>d d rappeler dizain j année cd petit adore osu...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15936</th>\n",
              "      <td>vallenato vallenato vallenato rien rien modern...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15937</th>\n",
              "      <td>sambora sambora connaître guitarist album proc...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15938</th>\n",
              "      <td>disco disco n n compil qualité énorme passez c...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15939</th>\n",
              "      <td>médiocre cd traditionnel piste trouver que mus...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15940 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53019092-1100-4b64-8466-4dd6769e2b91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53019092-1100-4b64-8466-4dd6769e2b91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53019092-1100-4b64-8466-4dd6769e2b91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-12d5f204-0936-4019-877f-c4dd692178ff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12d5f204-0936-4019-877f-c4dd692178ff')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-12d5f204-0936-4019-877f-c4dd692178ff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_cb18ca39-83f8-40ec-98e8-f56b332e5086\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_fr')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cb18ca39-83f8-40ec-98e8-f56b332e5086 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data_fr');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_fr",
              "summary": "{\n  \"name\": \"data_fr\",\n  \"rows\": 15940,\n  \"fields\": [\n    {\n      \"column\": \"ProcessedText\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11795,\n        \"samples\": [\n          \"reprise reprise reprise reprise num num num d d d j j j blue blue c c lover lover n n coup discographie radio ach\\u00e8te ach\\u00e9ter rough album r\\u00e9orchestrer ressembler arrangement amaigrissement enregsitrer voix qu jame l aucun amander us rien famille lear morceau aucun matriarche regarder originalit\\u00e9 choc phl\\u00e9toriqu of pann \\u00e9vident joe etter cocker manque been star sort life lot retravaill\\u00e9 sortir pratiquemer pochette d\\u00e9ception sublime spontan\\u00e9it\\u00e9 fil d\\u00e9couvrir decidemment cur poussif \\u00e9coute dernier s foi date mal lifting constater \\u00e2m inspiration the\",\n          \"clown n\\u00e9otruc faux bizarre skizo group accroch cirque c n musiqu protagoniste\",\n          \"morceal mis\\u00e9rable plein piti\\u00e9 disqu inspirer n\\u00e9ant vide ennui fuzati d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(data_fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is3-rzO1MOpl"
      },
      "source": [
        "## Creating the Multi-Lingual Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW7vDmD1jOOa"
      },
      "source": [
        "**Sample Data** A function that ensures equal number of Englsih and French Reviews in the Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-1tzoMXnLBsq"
      },
      "outputs": [],
      "source": [
        "def sample_data(df_en, df_fr, seed=42):\n",
        "    \"\"\"\n",
        "    Adjusts sampling to ensure an equal number of English and French samples,\n",
        "    maximizing the amount of data used while respecting the specified percentages.\n",
        "\n",
        "    Args:\n",
        "      Dataframe: The Pre-Processed English DataFrame\n",
        "      Dataframe: The Pre-Proecessed French DataFrame\n",
        "      Seed: Determines the random values\n",
        "\n",
        "    Returns:\n",
        "      Dataframe: The multilingual dataset\n",
        "    \"\"\"\n",
        "    # Determine the smallest number of positive or negative reviews in any language\n",
        "    min_samples = min(len(df_en[df_en['Sentiment'] == 'positive']),\n",
        "                      len(df_en[df_en['Sentiment'] == 'negative']),\n",
        "                      len(df_fr[df_fr['Sentiment'] == 'positive']),\n",
        "                      len(df_fr[df_fr['Sentiment'] == 'negative']))\n",
        "\n",
        "    # Sample from each subgroup to ensure balance\n",
        "    en_pos = df_en[df_en['Sentiment'] == 'positive'].sample(n=min_samples, random_state=seed)\n",
        "    en_neg = df_en[df_en['Sentiment'] == 'negative'].sample(n=min_samples, random_state=seed)\n",
        "    fr_pos = df_fr[df_fr['Sentiment'] == 'positive'].sample(n=min_samples, random_state=seed)\n",
        "    fr_neg = df_fr[df_fr['Sentiment'] == 'negative'].sample(n=min_samples, random_state=seed)\n",
        "\n",
        "    # Mark each sample with its language\n",
        "    en_pos['Language'] = 'English'\n",
        "    en_neg['Language'] = 'English'\n",
        "    fr_pos['Language'] = 'French'\n",
        "    fr_neg['Language'] = 'French'\n",
        "\n",
        "    # Combine all samples and shuffle them\n",
        "    balanced_dataset = pd.concat([en_pos, en_neg, fr_pos, fr_neg], ignore_index=True)\n",
        "    balanced_dataset = balanced_dataset.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
        "\n",
        "    return balanced_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XEHRIQpjiKI"
      },
      "source": [
        "### Building the Tf-Idf Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hYlu_dLYmyp"
      },
      "source": [
        "A Tf-Idf Matrix must be built to have the SVM and Naive Bayes to work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6rDF-GBjMYWx"
      },
      "outputs": [],
      "source": [
        "def preprocess_and_vectorize(df):\n",
        "    \"\"\"\n",
        "    Pre-Processes and vectorizes the text data in the DataFrame.\n",
        "\n",
        "    Args:\n",
        "      DataFrame: The Multi-Lingual Dataset\n",
        "\n",
        "    Returns:\n",
        "      DataFrame: Tf-Idf of the shape of the samples and feature representing the\n",
        "      vectorized text data.\n",
        "      DataFrame: The sentiment labels associated with each text\n",
        "      TfidfVectorizer: Contains the vocabulary and idf scores of each term\n",
        "      NumpyArray: An array of every text entry's language\n",
        "    \"\"\"\n",
        "    tfidf = TfidfVectorizer(max_features=10000)\n",
        "    X = tfidf.fit_transform(df['ProcessedText'])\n",
        "    y = df['Sentiment'].values\n",
        "    return X, y, tfidf, df['Language'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWIRxyjKjvpI"
      },
      "source": [
        "## Calculating the Specified Bias Metrics, Training the SVM and Naive Bayes, and Splitting the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3itT4SiscIgX"
      },
      "source": [
        "**Ensure Binary Labels**: Ensures the specified labels are binary, so the bias metrics function works as intended.\n",
        "\n",
        "**Calculate Bias Metrics**: Calculates the demographic parity ratiom equalized odds ratio, demographic parity difference, and equalized odds difference.\n",
        "\n",
        "**Map Labels**: Maps the sentiment labels to have binary classification.\n",
        "\n",
        "**Train and Evaluate:** Trains the SVM and Naive Bayes models, and calculating the corresponding precision, recall and f1-scores for each langugage. Also outputs the bias metrics for the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4cJSLLP1OglS"
      },
      "outputs": [],
      "source": [
        "def ensure_binary_labels(y):\n",
        "    \"\"\"\n",
        "    Ensures the specified labels are binary, so the bias metrics function works\n",
        "    as intended\n",
        "\n",
        "    Args:\n",
        "      DataFrame: The sentiment dataframe\n",
        "    \"\"\"\n",
        "    unique_labels = np.unique(y)\n",
        "    if set(unique_labels) == {0, 1} or set(unique_labels) == {-1, 1}:\n",
        "        return np.where(y == -1, 0, y)\n",
        "    else:\n",
        "        raise ValueError(\"Labels must be binary and in {0, 1} or {-1, 1}.\")\n",
        "\n",
        "def calculate_bias_metrics(y_true, y_pred, sensitive_features):\n",
        "    \"\"\"\n",
        "    Calculates the demographic parity ratiom equalized odds ratio,\n",
        "    demographic parity difference, and equalized odds difference.\n",
        "\n",
        "    Args:\n",
        "      DataFrame: Dataframe the contains the actual sentiment labels for the\n",
        "      specified text in the dataset\n",
        "      DataFrame: Dataframe the contains the predicted sentiment labels for the\n",
        "      specified text in the dataset\n",
        "      DataFrame: Contains the dataframe with the languages corresponding to\n",
        "      the sentiment labels\n",
        "    \"\"\"\n",
        "    y_true_binary = ensure_binary_labels(y_true)\n",
        "    y_pred_binary = ensure_binary_labels(y_pred)\n",
        "\n",
        "    m_dpr = demographic_parity_ratio(y_true_binary, y_pred_binary, sensitive_features=sensitive_features)\n",
        "    m_eqo = equalized_odds_ratio(y_true_binary, y_pred_binary, sensitive_features=sensitive_features)\n",
        "    m_dpr_2 = demographic_parity_difference(y_true_binary, y_pred_binary, sensitive_features=sensitive_features)\n",
        "    m_eqo_2 = equalized_odds_difference(y_true_binary, y_pred_binary, sensitive_features=sensitive_features)\n",
        "\n",
        "    print(f\"The demographic parity ratio is {m_dpr}\")\n",
        "    print(f\"The equalized odds ratio is {m_eqo}\")\n",
        "    print(f\"The demographic parity differece is {m_dpr_2}\")\n",
        "    print(f\"The equalized odds difference is {m_eqo_2}\")\n",
        "\n",
        "def map_labels(y):\n",
        "    \"\"\"\n",
        "    Maps the positve and negative setiments to be binary\n",
        "\n",
        "    Args:\n",
        "      DataFrame: The dataset without binary labels for sentiment\n",
        "\n",
        "    Return:\n",
        "      DataFrame: The dataset with binary labels\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    return np.where(y == 'positive', 1, 0)\n",
        "\n",
        "def objective(trial):\n",
        "    \"\"\"\n",
        "    Objective function for hyperparameter tuning using Optuna.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial): A trial is a process of evaluating an objective function.\n",
        "\n",
        "    Returns:\n",
        "        float: The accuracy of the model with the suggested parameters.\n",
        "    \"\"\"\n",
        "    # Selecting the model type\n",
        "    model_type = trial.suggest_categorical('model_type', ['SVM', 'NaiveBayes'])\n",
        "\n",
        "    # Configuring parameters for SVM\n",
        "    if model_type == 'SVM':\n",
        "        C = trial.suggest_loguniform('svm_C', 1e-10, 1e10)\n",
        "        kernel = trial.suggest_categorical('svm_kernel', ['linear', 'rbf', 'poly', 'sigmoid'])\n",
        "        gamma = trial.suggest_categorical('svm_gamma', ['scale', 'auto'])\n",
        "        model = SVC(C=C, kernel=kernel, gamma=gamma)\n",
        "\n",
        "    # Configuring parameters for Naive Bayes\n",
        "    else:\n",
        "        alpha = trial.suggest_float('nb_alpha', 1e-10, 10.0)\n",
        "        fit_prior = trial.suggest_categorical('nb_fit_prior', [True, False])\n",
        "        model = MultinomialNB(alpha=alpha, fit_prior=fit_prior)\n",
        "\n",
        "    # Training the model on the training dataset\n",
        "    model.fit(X_train, map_labels(y_train))\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_mapped = map_labels(y_pred)  # Ensure predictions are in binary format\n",
        "\n",
        "    # Calculate and return the accuracy\n",
        "    return accuracy_score(map_labels(y_test), y_pred_mapped)\n",
        "\n",
        "def train_and_evaluate_with_optuna(X_train, y_train, X_test, y_test, languages_test):\n",
        "    \"\"\"\n",
        "    Sets up and runs the hyperparameter optimization using Optuna, then evaluates the best model.\n",
        "\n",
        "    Args:\n",
        "        X_train, y_train: Training data and labels.\n",
        "        X_test, y_test: Testing data and labels.\n",
        "        languages_test: DataFrame containing the language data corresponding to y_test.\n",
        "\n",
        "    Uses Optuna to optimize the hyperparameters of either an SVM or Naive Bayes classifier.\n",
        "    \"\"\"\n",
        "    # Creating a study object to maximize the objective function\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(objective, n_trials=50)  # Adjust the number of trials based on resource availability\n",
        "\n",
        "    # Use the best model parameters to predict and evaluate\n",
        "    best_model = study.best_trial.user_attrs['model']\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    y_pred_mapped = map_labels(y_pred)  # Map labels to binary format\n",
        "\n",
        "    # Calculate and print bias metrics\n",
        "    calculate_bias_metrics(map_labels(y_test), y_pred_mapped, languages_test)\n",
        "\n",
        "    y_pred_final = np.where(y_pred_mapped == 1, 'positive', 'negative')\n",
        "    print(\"Results for the best model:\")\n",
        "    print(\"Overall Accuracy:\", accuracy_score(y_test, y_pred_final))\n",
        "    print(\"Overall Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred_final))\n",
        "\n",
        "    # Evaluating model performance for each language\n",
        "    for language in ['English', 'French']:\n",
        "        idx = languages_test == language\n",
        "        y_test_lang = y_test[idx]\n",
        "        y_pred_lang = y_pred_final[idx]\n",
        "\n",
        "        print(f\"Accuracy on {language}: {accuracy_score(y_test_lang, y_pred_lang)}\")\n",
        "        print(f\"Classification Report for {language}:\")\n",
        "        print(classification_report(y_test_lang, y_pred_lang))\n",
        "\n",
        "    print(\"----------------------------------------------------\")\n",
        "\n",
        "def train_and_evaluate(X_train, y_train, X_test, y_test, languages_test, model, model_name=\"Model\", use_random_search=False):\n",
        "    \"\"\"\n",
        "    Trains the SVM and Naive Bayes models, and calculates the corresponding\n",
        "    precision, recall, and f1-scores for each language. Also outputs the\n",
        "    bias metrics for the models. Optionally includes random search for hyperparameter tuning.\n",
        "\n",
        "    Args:\n",
        "      X_train, y_train: Training data and labels.\n",
        "      X_test, y_test: Testing data and labels.\n",
        "      languages_test: Array indicating the language of each test sample.\n",
        "      model: The machine learning model instance to be trained.\n",
        "      model_name: A name for the model for display purposes.\n",
        "      use_random_search: If True, perform random search to find optimal hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    y_train_mapped = map_labels(y_train)\n",
        "    y_test_mapped = map_labels(y_test)\n",
        "\n",
        "    if use_random_search:\n",
        "        # Define the parameter distribution for SVM\n",
        "        param_distributions = {\n",
        "            'C': np.logspace(-4, 4, 20),  # Regularization parameter\n",
        "            'kernel': ['linear', 'rbf', 'sigmoid'],  # Type of kernel\n",
        "            'gamma': ['scale', 'auto'] + list(np.logspace(-4, 1, 20))  # Kernel coefficient\n",
        "        }\n",
        "        # Setup the RandomizedSearchCV\n",
        "        random_search = RandomizedSearchCV(estimator=model, param_distributions=param_distributions,\n",
        "                                           n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "        random_search.fit(X_train, y_train_mapped)\n",
        "\n",
        "        # Using the best estimator found by RandomizedSearchCV\n",
        "        model = random_search.best_estimator_\n",
        "        print(f\"Best parameters found: {random_search.best_params_}\")\n",
        "        print(f\"Best cross-validation score: {random_search.best_score_:.2f}\")\n",
        "\n",
        "    else:\n",
        "        # Train the model as usual\n",
        "        model.fit(X_train, y_train_mapped)\n",
        "\n",
        "    # Predict on the test set using the trained or best model found\n",
        "    y_pred_mapped = model.predict(X_test)\n",
        "\n",
        "    # Calculate bias metrics\n",
        "    bias_metrics = calculate_bias_metrics(y_test_mapped, y_pred_mapped, languages_test)\n",
        "\n",
        "    # Convert predictions back to 'positive'/'negative' for reporting\n",
        "    y_pred = np.where(y_pred_mapped == 1, 'positive', 'negative')\n",
        "\n",
        "    print(f\"Results for {model_name}:\")\n",
        "    print(\"Overall Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Overall Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Accuracy and classification report by language\n",
        "    for language in ['English', 'French']:\n",
        "        idx = languages_test == language\n",
        "        y_test_lang = y_test[idx]\n",
        "        y_pred_lang = y_pred[idx]\n",
        "\n",
        "        print(f\"Accuracy on {language}: {accuracy_score(y_test_lang, y_pred_lang)}\")\n",
        "        print(f\"Classification Report for {language}:\")\n",
        "        print(classification_report(y_test_lang, y_pred_lang))\n",
        "\n",
        "    print(\"----------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFiVtNgUb2Lq"
      },
      "source": [
        "# Training the Music Data Using SVM and Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-8KTlK1cAlR"
      },
      "source": [
        "Splitting up the data, using an 80-20 training and validation split and calling the corresponding functions for a properly trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ALnxNIQpcjRx"
      },
      "outputs": [],
      "source": [
        "df_sampled = sample_data(data_en, data_fr)\n",
        "\n",
        "X, y, tfidf, languages = preprocess_and_vectorize(df_sampled)\n",
        "\n",
        "X_train, X_test, y_train, y_test, languages_train, languages_test = train_test_split(X, y, languages, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwnm_07LPC0j",
        "outputId": "1f67e869-5a90-4411-9478-2a4d72d1fb16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(31880, 3)\n"
          ]
        }
      ],
      "source": [
        "print(df_sampled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking the Hyperparameters"
      ],
      "metadata": {
        "id": "IaSm91WAR6ue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14e1Q4TUOhS1",
        "outputId": "ed749921-37c7-462b-b67c-ca9dcf5c6516"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-04-25 15:40:02,076] A new study created in memory with name: no-name-3c587e75-fbda-48a0-8cc5-ea4085a2e7d5\n",
            "[I 2024-04-25 15:40:02,106] Trial 0 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 9.978064474438852, 'nb_fit_prior': False}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 15:40:02,128] Trial 1 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 8.3281649430947, 'nb_fit_prior': False}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 15:40:02,149] Trial 2 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 7.3043382898505005, 'nb_fit_prior': False}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 15:40:02,170] Trial 3 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 7.486178784179179, 'nb_fit_prior': True}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 15:40:02,194] Trial 4 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 3.8369218405629093, 'nb_fit_prior': False}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 15:40:02,215] Trial 5 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 7.041689785837844, 'nb_fit_prior': False}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 15:40:02,238] Trial 6 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 9.313417772921435, 'nb_fit_prior': True}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 15:40:02,260] Trial 7 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 9.70114764111598, 'nb_fit_prior': False}. Best is trial 0 with value: 0.5039209535759097.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running hyperparameter optimization and model evaluation...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-cadda04430c8>:70: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('svm_C', 1e-10, 1e10)\n",
            "[I 2024-04-25 15:46:57,510] Trial 8 finished with value: 0.5039209535759097 and parameters: {'model_type': 'SVM', 'svm_C': 7.429608749911732e-05, 'svm_kernel': 'sigmoid', 'svm_gamma': 'scale'}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 15:46:57,540] Trial 9 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 7.450184595546536, 'nb_fit_prior': True}. Best is trial 0 with value: 0.5039209535759097.\n",
            "<ipython-input-9-cadda04430c8>:70: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('svm_C', 1e-10, 1e10)\n",
            "[I 2024-04-25 15:53:20,190] Trial 10 finished with value: 0.5039209535759097 and parameters: {'model_type': 'SVM', 'svm_C': 3859568647.185754, 'svm_kernel': 'poly', 'svm_gamma': 'auto'}. Best is trial 0 with value: 0.5039209535759097.\n",
            "<ipython-input-9-cadda04430c8>:70: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('svm_C', 1e-10, 1e10)\n",
            "[I 2024-04-25 15:59:44,235] Trial 11 finished with value: 0.5039209535759097 and parameters: {'model_type': 'SVM', 'svm_C': 1.131587750285519e-09, 'svm_kernel': 'linear', 'svm_gamma': 'scale'}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 15:59:44,266] Trial 12 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 1.027600272546585, 'nb_fit_prior': False}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 15:59:44,295] Trial 13 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 9.945523714714255, 'nb_fit_prior': False}. Best is trial 0 with value: 0.5039209535759097.\n",
            "<ipython-input-9-cadda04430c8>:70: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('svm_C', 1e-10, 1e10)\n",
            "[I 2024-04-25 16:13:11,429] Trial 14 finished with value: 0.5039209535759097 and parameters: {'model_type': 'SVM', 'svm_C': 5729451.708167416, 'svm_kernel': 'rbf', 'svm_gamma': 'auto'}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 16:13:11,479] Trial 15 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 4.746451368713181, 'nb_fit_prior': False}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 16:13:11,523] Trial 16 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 8.513157493416788, 'nb_fit_prior': False}. Best is trial 0 with value: 0.5039209535759097.\n",
            "[I 2024-04-25 16:13:11,569] Trial 17 finished with value: 0.5039209535759097 and parameters: {'model_type': 'NaiveBayes', 'nb_alpha': 5.919762953179162, 'nb_fit_prior': False}. Best is trial 0 with value: 0.5039209535759097.\n",
            "<ipython-input-9-cadda04430c8>:70: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  C = trial.suggest_loguniform('svm_C', 1e-10, 1e10)\n"
          ]
        }
      ],
      "source": [
        "print(\"Running hyperparameter optimization and model evaluation...\")\n",
        "train_and_evaluate_with_optuna(X_train, y_train, X_test, y_test, languages_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the model"
      ],
      "metadata": {
        "id": "WcYPGhB_SAUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC(kernel='linear')\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Train and evaluate models, including language-specific performance\n",
        "print(\"Evaluating SVM...\")\n",
        "train_and_evaluate(X_train, y_train, X_test, y_test, languages_test, svm_model, \"SVM\")\n",
        "\n",
        "print(\"Evaluating Naive Bayes...\")\n",
        "train_and_evaluate(X_train, y_train, X_test, y_test, languages_test, nb_model, \"Naive Bayes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh8e3RXaRxnH",
        "outputId": "2a456526-dd3d-4d6e-af02-4535cea23e8b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating SVM...\n",
            "The demographic parity ratio is 0.9390938937751449\n",
            "The equalized odds ratio is 0.4708679956050855\n",
            "The demographic parity differece is 0.031663550059306544\n",
            "The equalized odds difference is 0.09143453850117986\n",
            "Results for SVM:\n",
            "Overall Accuracy: 0.8800188205771644\n",
            "Overall Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.87      0.88      3213\n",
            "    positive       0.87      0.89      0.88      3163\n",
            "\n",
            "    accuracy                           0.88      6376\n",
            "   macro avg       0.88      0.88      0.88      6376\n",
            "weighted avg       0.88      0.88      0.88      6376\n",
            "\n",
            "Accuracy on English: 0.8482003129890454\n",
            "Classification Report for English:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.83      0.85      1603\n",
            "    positive       0.83      0.87      0.85      1592\n",
            "\n",
            "    accuracy                           0.85      3195\n",
            "   macro avg       0.85      0.85      0.85      3195\n",
            "weighted avg       0.85      0.85      0.85      3195\n",
            "\n",
            "Accuracy on French: 0.9119773656082992\n",
            "Classification Report for French:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.91      0.92      0.91      1610\n",
            "    positive       0.92      0.91      0.91      1571\n",
            "\n",
            "    accuracy                           0.91      3181\n",
            "   macro avg       0.91      0.91      0.91      3181\n",
            "weighted avg       0.91      0.91      0.91      3181\n",
            "\n",
            "----------------------------------------------------\n",
            "Evaluating Naive Bayes...\n",
            "The demographic parity ratio is 0.8028725560706311\n",
            "The equalized odds ratio is 0.3170235777633571\n",
            "The demographic parity differece is 0.11469793998895045\n",
            "The equalized odds difference is 0.1712766823076297\n",
            "Results for Naive Bayes:\n",
            "Overall Accuracy: 0.8622961104140527\n",
            "Overall Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.89      0.84      0.86      3213\n",
            "    positive       0.84      0.89      0.87      3163\n",
            "\n",
            "    accuracy                           0.86      6376\n",
            "   macro avg       0.86      0.86      0.86      6376\n",
            "weighted avg       0.86      0.86      0.86      6376\n",
            "\n",
            "Accuracy on English: 0.831924882629108\n",
            "Classification Report for English:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.75      0.82      1603\n",
            "    positive       0.78      0.92      0.84      1592\n",
            "\n",
            "    accuracy                           0.83      3195\n",
            "   macro avg       0.84      0.83      0.83      3195\n",
            "weighted avg       0.84      0.83      0.83      3195\n",
            "\n",
            "Accuracy on French: 0.8928010059729645\n",
            "Classification Report for French:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.92      0.90      1610\n",
            "    positive       0.91      0.86      0.89      1571\n",
            "\n",
            "    accuracy                           0.89      3181\n",
            "   macro avg       0.89      0.89      0.89      3181\n",
            "weighted avg       0.89      0.89      0.89      3181\n",
            "\n",
            "----------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUZzDKf8b0Ss"
      },
      "source": [
        "# Training the DVD Data Using SVM and Naive-Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHHoGSwJPNnd",
        "outputId": "d918ee65-be85-4627-ebf1-f791400228c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(18716, 3)\n"
          ]
        }
      ],
      "source": [
        "print(sample_data(data_en_dvd, data_fr_dvd).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3kkT4jh7619",
        "outputId": "4d6a776d-558b-4b15-a7c2-d19f24d82180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating SVM...\n",
            "The demographic parity ratio is 0.9938598414836628\n",
            "The equalized odds ratio is 0.8510878861234726\n",
            "The demographic parity differece is 0.003132134051684776\n",
            "The equalized odds difference is 0.023429677896095652\n",
            "Results for SVM:\n",
            "Overall Accuracy: 0.8629807692307693\n",
            "Overall Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.85      0.86      1873\n",
            "    positive       0.86      0.87      0.86      1871\n",
            "\n",
            "    accuracy                           0.86      3744\n",
            "   macro avg       0.86      0.86      0.86      3744\n",
            "weighted avg       0.86      0.86      0.86      3744\n",
            "\n",
            "Accuracy on English: 0.8553191489361702\n",
            "Classification Report for English:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.84      0.85       947\n",
            "    positive       0.84      0.87      0.86       933\n",
            "\n",
            "    accuracy                           0.86      1880\n",
            "   macro avg       0.86      0.86      0.86      1880\n",
            "weighted avg       0.86      0.86      0.86      1880\n",
            "\n",
            "Accuracy on French: 0.8707081545064378\n",
            "Classification Report for French:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.87      0.87       926\n",
            "    positive       0.87      0.88      0.87       938\n",
            "\n",
            "    accuracy                           0.87      1864\n",
            "   macro avg       0.87      0.87      0.87      1864\n",
            "weighted avg       0.87      0.87      0.87      1864\n",
            "\n",
            "----------------------------------------------------\n",
            "Evaluating Naive Bayes...\n",
            "The demographic parity ratio is 0.897649662412355\n",
            "The equalized odds ratio is 0.5970548945679721\n",
            "The demographic parity differece is 0.05395169390923199\n",
            "The equalized odds difference is 0.07361087987301038\n",
            "Results for Naive Bayes:\n",
            "Overall Accuracy: 0.8541666666666666\n",
            "Overall Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.85      0.85      1873\n",
            "    positive       0.85      0.85      0.85      1871\n",
            "\n",
            "    accuracy                           0.85      3744\n",
            "   macro avg       0.85      0.85      0.85      3744\n",
            "weighted avg       0.85      0.85      0.85      3744\n",
            "\n",
            "Accuracy on English: 0.8468085106382979\n",
            "Classification Report for English:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.82      0.84       947\n",
            "    positive       0.83      0.88      0.85       933\n",
            "\n",
            "    accuracy                           0.85      1880\n",
            "   macro avg       0.85      0.85      0.85      1880\n",
            "weighted avg       0.85      0.85      0.85      1880\n",
            "\n",
            "Accuracy on French: 0.8615879828326181\n",
            "Classification Report for French:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.84      0.89      0.86       926\n",
            "    positive       0.89      0.83      0.86       938\n",
            "\n",
            "    accuracy                           0.86      1864\n",
            "   macro avg       0.86      0.86      0.86      1864\n",
            "weighted avg       0.86      0.86      0.86      1864\n",
            "\n",
            "----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "df_sampled = sample_data(data_en_dvd, data_fr_dvd)\n",
        "X, y, tfidf, languages = preprocess_and_vectorize(df_sampled)\n",
        "\n",
        "# Split the data, ensuring languages array is split consistently with X and y\n",
        "X_train, X_test, y_train, y_test, languages_train, languages_test = train_test_split(X, y, languages, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize models\n",
        "svm_model = SVC(kernel='linear')\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Train and evaluate models, including language-specific performance\n",
        "print(\"Evaluating SVM...\")\n",
        "train_and_evaluate(X_train, y_train, X_test, y_test, languages_test, svm_model, \"SVM\")\n",
        "\n",
        "print(\"Evaluating Naive Bayes...\")\n",
        "train_and_evaluate(X_train, y_train, X_test, y_test, languages_test, nb_model, \"Naive Bayes\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwqkjHT_bq8z"
      },
      "source": [
        "# Training the Books Data Using SVM and Naive-Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdUCjOV-PWrz",
        "outputId": "6709b08e-a59a-4255-b161-09dac7ffc423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(65740, 3)\n"
          ]
        }
      ],
      "source": [
        "print(sample_data(data_en_books, data_fr_books).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmGph4GA-HjI",
        "outputId": "ce65d13b-6d79-4b1a-bc30-3cd11de7d081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating SVM...\n",
            "The demographic parity ratio is 0.9883989554152294\n",
            "The equalized odds ratio is 0.7175357836302722\n",
            "The demographic parity differece is 0.005885656300913311\n",
            "The equalized odds difference is 0.04176079944506905\n",
            "Results for SVM:\n",
            "Overall Accuracy: 0.8768634012777609\n",
            "Overall Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.88      0.87      0.88      6565\n",
            "    positive       0.87      0.88      0.88      6583\n",
            "\n",
            "    accuracy                           0.88     13148\n",
            "   macro avg       0.88      0.88      0.88     13148\n",
            "weighted avg       0.88      0.88      0.88     13148\n",
            "\n",
            "Accuracy on English: 0.8562471325890809\n",
            "Classification Report for English:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.85      0.86      3294\n",
            "    positive       0.85      0.86      0.86      3245\n",
            "\n",
            "    accuracy                           0.86      6539\n",
            "   macro avg       0.86      0.86      0.86      6539\n",
            "weighted avg       0.86      0.86      0.86      6539\n",
            "\n",
            "Accuracy on French: 0.8972613103343925\n",
            "Classification Report for French:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.89      0.90      3271\n",
            "    positive       0.90      0.90      0.90      3338\n",
            "\n",
            "    accuracy                           0.90      6609\n",
            "   macro avg       0.90      0.90      0.90      6609\n",
            "weighted avg       0.90      0.90      0.90      6609\n",
            "\n",
            "----------------------------------------------------\n",
            "Evaluating Naive Bayes...\n",
            "The demographic parity ratio is 0.960017133498883\n",
            "The equalized odds ratio is 0.6516086104267448\n",
            "The demographic parity differece is 0.020789378514114998\n",
            "The equalized odds difference is 0.06472845489339168\n",
            "Results for Naive Bayes:\n",
            "Overall Accuracy: 0.8554913294797688\n",
            "Overall Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.86      0.85      0.85      6565\n",
            "    positive       0.85      0.86      0.86      6583\n",
            "\n",
            "    accuracy                           0.86     13148\n",
            "   macro avg       0.86      0.86      0.86     13148\n",
            "weighted avg       0.86      0.86      0.86     13148\n",
            "\n",
            "Accuracy on English: 0.8365193454656675\n",
            "Classification Report for English:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.85      0.81      0.83      3294\n",
            "    positive       0.82      0.86      0.84      3245\n",
            "\n",
            "    accuracy                           0.84      6539\n",
            "   macro avg       0.84      0.84      0.84      6539\n",
            "weighted avg       0.84      0.84      0.84      6539\n",
            "\n",
            "Accuracy on French: 0.8742623694961417\n",
            "Classification Report for French:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.88      0.87      3271\n",
            "    positive       0.88      0.87      0.87      3338\n",
            "\n",
            "    accuracy                           0.87      6609\n",
            "   macro avg       0.87      0.87      0.87      6609\n",
            "weighted avg       0.87      0.87      0.87      6609\n",
            "\n",
            "----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "df_sampled = sample_data(data_en_books, data_fr_books)\n",
        "X, y, tfidf, languages = preprocess_and_vectorize(df_sampled)\n",
        "\n",
        "X_train, X_test, y_train, y_test, languages_train, languages_test = train_test_split(X, y, languages, test_size=0.2, random_state=42)\n",
        "\n",
        "svm_model = SVC(kernel='linear')\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "print(\"Evaluating SVM...\")\n",
        "train_and_evaluate(X_train, y_train, X_test, y_test, languages_test, svm_model, \"SVM\")\n",
        "\n",
        "print(\"Evaluating Naive Bayes...\")\n",
        "train_and_evaluate(X_train, y_train, X_test, y_test, languages_test, nb_model, \"Naive Bayes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xkf5NKYc_em"
      },
      "source": [
        "# Transforming the Notebook into a Latex File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2xXe57Lc2cx"
      },
      "outputs": [],
      "source": [
        "!apt-get -q install texlive-xetex texlive-fonts-recommended texlive-plain-generic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BdLtTkpdEaT",
        "outputId": "71ad46f6-94a2-40b7-ec53-fc09dfde5303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook /content/drive/My Drive/Colab Notebooks/Analyzing Language Bias Between French and English in Conventional Multilingual Sentiment Analysis Models.ipynb to pdf\n",
            "[NbConvertApp] Writing 101974 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 99654 bytes to /content/drive/My Drive/Colab Notebooks/Analyzing Language Bias Between French and English in Conventional Multilingual Sentiment Analysis Models.pdf\n"
          ]
        }
      ],
      "source": [
        "!jupyter nbconvert --to pdf \"/content/drive/My Drive/Colab Notebooks/Analyzing Language Bias Between French and English in Conventional Multilingual Sentiment Analysis Models.ipynb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "zLoqKkRVdOmt",
        "outputId": "8cfc898b-629b-4362-c193-c8d2594b23ab"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_d8b1e13d-8369-4feb-9214-9d18354ba620\", \"Analyzing Language Bias Between French and English in Conventional Multilingual Sentiment Analysis Models.pdf\", 99654)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "files.download(f\"/content/drive/My Drive/Colab Notebooks/Analyzing Language Bias Between French and English in Conventional Multilingual Sentiment Analysis Models.pdf\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYi3J2ROF/c9KoACqUjIvM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}